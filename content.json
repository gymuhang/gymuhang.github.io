{"pages":[{"title":"关于","date":"2020-04-22T11:41:51.710Z","path":"about/index.html","text":"是伐啦多费口舌龙卷风胜多负少的发生率的方式来电风扇大量发送杜绝浪费时间都浪费是点击发了啥豆浆放了时代峻峰"},{"title":"分类","date":"2020-04-22T11:40:00.104Z","path":"categories/index.html","text":""},{"title":"标签","date":"2020-04-22T11:40:06.281Z","path":"tags/index.html","text":""}],"posts":[{"title":"Nacos 实战","date":"2020-04-22T01:24:57.128Z","path":"wiki/nacos/nacos/","text":"一款异步的事件驱动的网络应用程序框架 阻塞 发起 —-》阻塞…. 阻塞 —–》完成 检查…检查—-》阻塞—-》完成 ​ 阻塞与非阻塞是进程在访问数据的时候，数据是否准备就绪的处理方式，数据没准备好，要么等待数据准备好处理，要么直接返回即不处理 同步 双方的动作是经过双方协调的，步调一致的 异步 双方并不需要协调，都可以随意进行各自的操作 ​ 同步与异步都是基于应用程序和操作系统处理IO时间采用的方式，要么应用程序直接参与IO操作，要么IO操作交给操作系统去处理，应用程序只要等待通知 事件驱动：指在持续事务管理过程中，进行决策的一种策略，即跟随当前时间点上出现的事件，调动可用资源，执行相关任务，使不断出现的问题得以解决，防止事务堆积。（就是回调） bio：阻塞同步io nio：非阻塞io aio：非阻塞异步io ​ 为什么Netty使用NIO而不是AIO？ Netty不看重Windows上的使用，在Linux系统上，AIO的底层实现仍使用EPOLL，没有很好实现AIO，因此在性能上没有明显的优势，而且被JDK封装了一层不容易深度优化 Netty整体架构是reactor模型, 而AIO是proactor模型, 混合在一起会非常混乱,把AIO也改造成reactor模型看起来是把epoll绕个弯又绕回来 AIO还有个缺点是接收数据需要预先分配缓存, 而不是NIO那种需要接收时才需要分配缓存, 所以对连接数量非常大但流量小的情况, 内存浪费很多 Linux上AIO不够成熟，处理回调结果速度跟不到处理需求，比如外卖员太少，顾客太多，供不应求，造成处理速度有瓶颈（待验证） BIO是面向流的，一位置每次从流中读取字节，直至读取完全部字节，他们没有缓存在任何地方，因此是不能前后移动流中数据，需要移动或者操作的话需要将其缓存到缓冲区。 NIO是面向缓冲区的，数据读取到一个稍后处理的缓冲区，当然可以前后移动或者操作缓冲区数据。 1.组件1.Channel​ Java NIO的基本构造，代表一个到实体的开放连接，如读操作和写操作 2.回调​ 异步处理的后续操作 3.Future​ 提供了另一种操作完成时通知应用程序的方式，可以看作是异步操作结果的占位符，它在未来的某个时刻完成，并提供对其结果的访问，相对于jdk netty提供了自己的实现ChannelFuture 用的是ChannelFutureListener，即监听器 4.事件和ChannelHandler​ 事件就是 网络事件的出入站等，而ChannelHandler 则是对应具体事件的处理 5.放在一起​ Netty的异步编程模型建立在Future和回调上，并将事件派发到ChannelHandlerf方法。 ​ 触发事件 通过 抽象的Selector 进行派发代码，在内部为每个channel 分配EventLoop （线程驱动），来处理所有的事件 2.第一个应用3.netty的组件和设计1.Channel EventLoop ChannelFuture 网络抽象​ Channel 一个连接 socket （提供了很多默认实现） ​ EventLoop 控制流、多线程、并发 （相等于线程，EventLoop 相当于线程池）一个Channel 绑定一个 ​ EventLoop ，但是一个EventLoop 可能会分配给一个或多个Channel ​ ChannelFuture 异步通知 2.ChannelHandler ChannelPipeline 管理数据流以及执行应用程序处理逻辑​ ChannelHandler ​ ①入站和出站的数据的程序逻辑容器，②编解码，③异常通知，④channel编程活动或非活动的通知，⑤ ​ 注册Eventloop，或者注销 Eventloop的通知，⑥用户自定义的事件通知 ​ 常用的 ChannelHandlerAdapter ​ ChannelInboundHandlerAdapter ​ ChannelOutboundHandlerAdapter ​ ChannelDuplexHandler ​ 编码器、解码器 ​ SimpleChannelInboundHandler T 需要处理的数据类型 ctx是可以继续传递下去 ​ ChannelPipeline （拦截过滤器实现） ​ 是ChannelHandler 处理链的容器 出站和入站方向相反 ​ 引导 ​ 为应用程序网络层配置提供容器，将进程绑定和端口或者将进程连接到某个指定主机的指定端口进程，面 ​ 向连接的协议，如 tcp ​ Bootstrap 一个EventLoopGroup ​ ServerBootstrap 两个EventLoopGroup （当然也可以共用一个） 一个用来监听服务，一个用来处理传入 ​ 客户端的连接 4.传输​ OIO（阻塞）、NIO（非阻塞）、Local（JVM内部的异步通信）、Embedded（测试channelHandler） ​ netty的api 比较统一，只需要少量修改 1.传输的api​ channel 线程安全的 ​ EventLoop eventLoop(); 返回分配的eventLoop ​ ChannelPipeline pipeline(); 返回分配的ChannelPipeline ​ boolean isActive(); 是否是活动的 ​ SocketAddress localAddress(); 返回本地的 SocketAddress ​ SocketAddress remoteAddress(); 返回远程的 SocketAddress ​ ChannelFuture write(Object var1); 将数据写到远程节点，这个数据传递给 ChannelPipeline 写队列的第一个 ​ Channel flush(); 将之前写的数据 清空缓冲区数据 冲刷到 底层传输 ​ ChannelFuture writeAndFlush(Object var1); 写然后冲刷 2.内置的传输​ 提供的开箱可用的传输 ​ 1.NIO io.netty.channel.socket.nio java NIO为基础 ​ 选择器背后就是个注册表，当channel 发生变化时，得到通知，可能的变化： ​ 新的channel已经接受并且就绪 OP_ACCEPT ​ channel连接已经完成 OP_CONNECT ​ channel有已经就绪的可供读取的数据 OP_READ ​ channel可用于写数据 OP_WRITE ​ zero-copy（直接将数据从文件移动到网络接口） ​ 2.Epoll io.netty.channel.epoll 基于JNI驱动的epoll()和非阻塞IO，在linux上更快，比NIO更快 ​ linux jdk nio 使用了这一特性，但是netty 做了自己的统一封装 （使用了更加轻量的中断）比jdk 更高效 ​ 替换的话 Epoll 的serverSocket和EvevtLoopGroup ​ 3.OIO io.netty.channme.socket.oio 使用java.net 包的阻塞流 ​ 适用于某些阻塞的调用库（jdbc）等 ​ 4.Local io.netty.channel.local 在JVM内部通过管道进行通信的本地传输​ ​ 5.Embedded io.netty.channel.embedded Embedded传输，允许使用channelhandler不是真正的网络传输，为 ​ 了测试channelHandler 传输 TCP UDP SCT UDT NIO √ √ √ √ Epoll（仅linux） √ √ × × OIO √ √ √ √","tags":[],"categories":[{"name":"nacos","slug":"nacos","permalink":"http://yoursite.com/categories/nacos/"}]},{"title":"netty源码解析","date":"2020-04-22T01:24:57.128Z","path":"wiki/netty/netty-action/","text":"一款异步的事件驱动的网络应用程序框架 阻塞 发起 —-》阻塞…. 阻塞 —–》完成 检查…检查—-》阻塞—-》完成 ​ 阻塞与非阻塞是进程在访问数据的时候，数据是否准备就绪的处理方式，数据没准备好，要么等待数据准备好处理，要么直接返回即不处理 同步 双方的动作是经过双方协调的，步调一致的 异步 双方并不需要协调，都可以随意进行各自的操作 ​ 同步与异步都是基于应用程序和操作系统处理IO时间采用的方式，要么应用程序直接参与IO操作，要么IO操作交给操作系统去处理，应用程序只要等待通知 事件驱动：指在持续事务管理过程中，进行决策的一种策略，即跟随当前时间点上出现的事件，调动可用资源，执行相关任务，使不断出现的问题得以解决，防止事务堆积。（就是回调） bio：阻塞同步io nio：非阻塞io aio：非阻塞异步io ​ 为什么Netty使用NIO而不是AIO？ Netty不看重Windows上的使用，在Linux系统上，AIO的底层实现仍使用EPOLL，没有很好实现AIO，因此在性能上没有明显的优势，而且被JDK封装了一层不容易深度优化 Netty整体架构是reactor模型, 而AIO是proactor模型, 混合在一起会非常混乱,把AIO也改造成reactor模型看起来是把epoll绕个弯又绕回来 AIO还有个缺点是接收数据需要预先分配缓存, 而不是NIO那种需要接收时才需要分配缓存, 所以对连接数量非常大但流量小的情况, 内存浪费很多 Linux上AIO不够成熟，处理回调结果速度跟不到处理需求，比如外卖员太少，顾客太多，供不应求，造成处理速度有瓶颈（待验证） BIO是面向流的，一位置每次从流中读取字节，直至读取完全部字节，他们没有缓存在任何地方，因此是不能前后移动流中数据，需要移动或者操作的话需要将其缓存到缓冲区。 NIO是面向缓冲区的，数据读取到一个稍后处理的缓冲区，当然可以前后移动或者操作缓冲区数据。 1.组件1.Channel​ Java NIO的基本构造，代表一个到实体的开放连接，如读操作和写操作 2.回调​ 异步处理的后续操作 3.Future​ 提供了另一种操作完成时通知应用程序的方式，可以看作是异步操作结果的占位符，它在未来的某个时刻完成，并提供对其结果的访问，相对于jdk netty提供了自己的实现ChannelFuture 用的是ChannelFutureListener，即监听器 4.事件和ChannelHandler​ 事件就是 网络事件的出入站等，而ChannelHandler 则是对应具体事件的处理 5.放在一起​ Netty的异步编程模型建立在Future和回调上，并将事件派发到ChannelHandlerf方法。 ​ 触发事件 通过 抽象的Selector 进行派发代码，在内部为每个channel 分配EventLoop （线程驱动），来处理所有的事件 2.第一个应用3.netty的组件和设计1.Channel EventLoop ChannelFuture 网络抽象​ Channel 一个连接 socket （提供了很多默认实现） ​ EventLoop 控制流、多线程、并发 （相等于线程，EventLoop 相当于线程池）一个Channel 绑定一个 ​ EventLoop ，但是一个EventLoop 可能会分配给一个或多个Channel ​ ChannelFuture 异步通知 2.ChannelHandler ChannelPipeline 管理数据流以及执行应用程序处理逻辑​ ChannelHandler ​ ①入站和出站的数据的程序逻辑容器，②编解码，③异常通知，④channel编程活动或非活动的通知，⑤ ​ 注册Eventloop，或者注销 Eventloop的通知，⑥用户自定义的事件通知 ​ 常用的 ChannelHandlerAdapter ​ ChannelInboundHandlerAdapter ​ ChannelOutboundHandlerAdapter ​ ChannelDuplexHandler ​ 编码器、解码器 ​ SimpleChannelInboundHandler T 需要处理的数据类型 ctx是可以继续传递下去 ​ ChannelPipeline （拦截过滤器实现） ​ 是ChannelHandler 处理链的容器 出站和入站方向相反 ​ 引导 ​ 为应用程序网络层配置提供容器，将进程绑定和端口或者将进程连接到某个指定主机的指定端口进程，面 ​ 向连接的协议，如 tcp ​ Bootstrap 一个EventLoopGroup ​ ServerBootstrap 两个EventLoopGroup （当然也可以共用一个） 一个用来监听服务，一个用来处理传入 ​ 客户端的连接 4.传输​ OIO（阻塞）、NIO（非阻塞）、Local（JVM内部的异步通信）、Embedded（测试channelHandler） ​ netty的api 比较统一，只需要少量修改 1.传输的api​ channel 线程安全的 ​ EventLoop eventLoop(); 返回分配的eventLoop ​ ChannelPipeline pipeline(); 返回分配的ChannelPipeline ​ boolean isActive(); 是否是活动的 ​ SocketAddress localAddress(); 返回本地的 SocketAddress ​ SocketAddress remoteAddress(); 返回远程的 SocketAddress ​ ChannelFuture write(Object var1); 将数据写到远程节点，这个数据传递给 ChannelPipeline 写队列的第一个 ​ Channel flush(); 将之前写的数据 清空缓冲区数据 冲刷到 底层传输 ​ ChannelFuture writeAndFlush(Object var1); 写然后冲刷 2.内置的传输​ 提供的开箱可用的传输 ​ 1.NIO io.netty.channel.socket.nio java NIO为基础 ​ 选择器背后就是个注册表，当channel 发生变化时，得到通知，可能的变化： ​ 新的channel已经接受并且就绪 OP_ACCEPT ​ channel连接已经完成 OP_CONNECT ​ channel有已经就绪的可供读取的数据 OP_READ ​ channel可用于写数据 OP_WRITE ​ zero-copy（直接将数据从文件移动到网络接口） ​ 2.Epoll io.netty.channel.epoll 基于JNI驱动的epoll()和非阻塞IO，在linux上更快，比NIO更快 ​ linux jdk nio 使用了这一特性，但是netty 做了自己的统一封装 （使用了更加轻量的中断）比jdk 更高效 ​ 替换的话 Epoll 的serverSocket和EvevtLoopGroup ​ 3.OIO io.netty.channme.socket.oio 使用java.net 包的阻塞流 ​ 适用于某些阻塞的调用库（jdbc）等 ​ 4.Local io.netty.channel.local 在JVM内部通过管道进行通信的本地传输​ ​ 5.Embedded io.netty.channel.embedded Embedded传输，允许使用channelhandler不是真正的网络传输，为 ​ 了测试channelHandler 传输 TCP UDP SCT UDT NIO √ √ √ √ Epoll（仅linux） √ √ × × OIO √ √ √ √","tags":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/tags/netty/"}],"categories":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/categories/netty/"}]},{"title":"Netty-ByteBuf","date":"2020-02-24T00:31:59.857Z","path":"wiki/netty/Netty-new笔记/","text":"ByteBuf常见问题 内存的类别有哪些？ 如何减少多线程内存分配之间的竞争？ 不同大小的内存是如何进行分配的？ ByteBuf 结构及重要API Bytebuf 结构 readerIndex 读指针 writerIndex 写指针 capacity 容量 maxCapacity 最大容量 ByteBuf 分类 Pooled 和 Unpooled Pooled 从预先分配好的一块内存，去取一段连续内存封装成ByteBuf, 返回给应用程序 Unpooled 每次进行内存分配时，直接调用系统API，向操作系统申请一块内存。 Unsafe 和 非Unsafe Unsafe (JDK里有unsafe对象，他可以直接拿到对象内存地址，基于内存地址可以进行一些读写操作) 如果是一个Unsafe类型的bytebuf, 可以直接拿到ByteBuf在 JVM里的具体的内存，可以直接调用jdk的unsafe进行读写。 非Unsafe 不会依赖到JDK底层unsafe的对象 Heap 和 Direct Heap 直接在堆上进行内存分配，分配的内存受GC管理，不需要手动释放 Direct 直接调用JDK的API进行内存分配，不受JVM控制，所以最终不会参与GC过程，需要手动释放。 ByteBufAllocator 内存分配管理器 AbstractByteBufAllocator 是实现了 ByteBufAllocator 两大子类 UnpooledByteBufAallocator/PooledByteBufAllocator","tags":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/tags/netty/"}],"categories":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/categories/netty/"}]},{"title":"reactor guid","date":"2020-01-10T05:47:02.197Z","path":"wiki/reactor/reactor_3_guid_翻译不全/","text":"About the Documentation本节简要概述了Reactor参考文档。不需要一行一行地阅读本指南，每一节都是独立的，尽管他们经常互相引用。 Getting StartedIntroducing ReactorReactor是JVM上的完全非阻塞的响应式编程框架，支持有效的需求管理（通过背压的方式）。它直接与Java 8的函数式API集成，特别是CompletableFuture、Stream和Duration。它提供了可组合的异步序列（asynchronous sequence）API：Flux（用于[N]个元素）和Mono（用于 [0|1]个元素）。广泛实现了Reactive Streams。使用reactor-netty，Reactor也支持非阻塞的进程间通信。配合微服务架构，Reactor Netty为HTTP（包括Websockets）、TCP和UDP提供了背压的网络引擎。完全支持响应式的Encoding和Decoding。 PrerequisitesReactor Core最低支持Java 8。它依赖org.reactivestreams:reactive-streams:1.0.2。 Android支持： Reactor 3没有正式支持Android（RxJava 2支持） 在Android SDK 26以上可以工作得很好 Introduction to Reactive ProgrammingReactor是响应式编程范式的一个实现，可以概括为：响应式编程是关于数据流和变化传播（the propagation of change）的异步编程范式。这意味着可以通过采用的编程语言轻松地表达静态（比如数组）或者动态（比如事件发送器）的数据流。见Reactive_programming Microsoft最先在.NET ecosystem增加了Reactive Extensions(Rx)库。然后，RxJava在JVM上实现了响应式编程。后来，通过Reactive Streams实现了Java上的标准化-Flow类定义的接口集和交互规则集成到了Java 9内。响应式编程范式通常在面向对象的语言中出现，是Observer设计模式的扩展。比较一下响应式流和Iterator设计模式，一个主要不同点是，Iterator是pull-based的，而响应式流是push-based。使用一个迭代器是一种命令式的编程模式，尽管访问值的方法完全是Iterable的责任。开发人员可以选择何时访问序列中的next()项。而响应式流，是发布-订阅模式的。发布者提醒订阅者来了新值，这种push是响应式的关键。除了推送值，还以明确定义的方式，涵盖错误处理和完成。通过调用onNext，发布者将新值推送给订阅者。也可以通过调用onError发送一个错误信号，或者通过onComplete完成。错误和完成都会终止序列，可以概括为： 12onNext x 0..N [onError | onComplete]1 这种方法非常灵活，它支持没有值、一个值和n个值（包括无限的值序列，比如时钟的连续滴答）。 但是，为什么需要一个异步的响应式库呢？ Blocking Can Be Wasteful现代程序可以覆盖大量并发用户，虽然硬件性能在持续提升，可软件性能还是一个关键问题。有两种办法提高程序性能： parallelize：采用更多线程和更多硬件资源 seek more efficiency：寻求当前资源的更高效率 一般来说，Java程序都是阻塞式的。容易达到性能瓶颈，就需要更多线程，运行类似的阻塞代码。这样做，很快就会出现争用和并发问题。更糟糕的是，阻塞浪费资源。如果仔细观察，一旦程序涉及延迟（特别是I/O，比如数据库操作和网络调用），资源就会被浪费-因为线程处于空闲或者等待数据的状态。 Asynchronicity to the Rescue?也可以编写异步的、非阻塞的代码，使用相同的底层资源切换到其他活动任务，等异步处理执行完成再切换回来。在JVM内，怎么写异步代码呢？ Callbacks：异步方法没有返回值，但是需要额外的回调参数（lambda或者匿名类），结果有效时就调用该参数。比如Swing中的EventListener Futures：异步方法立即返回Future。异步过程计算T的值，Future对象包装了对值的访问。该值不会立即有效，值有效以后才可以拉取（poll）。比如运行Callable任务的ExecutorService使用Future对象 这两种方法都有局限性。Callbacks很难组合到一起。阅读和维护起来也很困难。 From Imperative to Reactive Programming诸如Reactor这样的响应式库不但解决上述缺点，还关注其他方面： 组合性和可读性 数据作为流（flow），有丰富的operators subscribe前什么都没发生 Backpressure，消费者向生产者发送明确的信号，表明生产得太快了 与并发无关的高级抽象 Composability and Readabilitycomposability是指有能力编排多个异步任务，前一个任务的结果就是后续任务的输入，或者使用fork-join执行几个任务，也可以重用任务，把它作为更高级系统的组件。编排任务的能力与代码的可读性和可维护性紧密相关。随着异步过程层级的数量和复杂性的增加，编写和阅读代码都变得越来越难。正如我们所看到的，回调很简单，但它的一个主要缺点是，对于复杂的过程，你需要在回调中执行回调，他们嵌套在一起（Callback Hell）。Reactor提供了丰富的组合选项，代码反应了抽象过程的组织，全都位于同一级（嵌套最小化）。 The Assembly Line Analogy你可以想象为，响应式程序里的数据在装配线上移动。Reactor既是传送带，又是工作站。原材料从源注入（Publisher），最终的成品推送给消费者（Subscriber）。原材料经历各种转换和其他中间步骤，或者是大型装配线上的一部分和其他部件聚合到一起。如果在某一点出现了故障或者堵塞（也许花费了太长时间），受影响的工作站可以向上游信号以限制原材料的流动。 OperatorsReactor中，operators就是装配线类比中的工作站。每个operator都会向Publisher添加行为，并把前一步的Publisher包装成新的实例。整个链就这样形成了，数据从第一个Publisher沿着链向后移动，由每个link转发。最终，Subscriber完成了该过程。记住，在Subscriber订阅Publisher前，什么都没发生。Reactive Streams规范根本没有指定任何operators，Reactor的最佳附加值就是添加了丰富的operators。他们涉及很多方面，从简单的转换、过滤到复杂的编排和错误处理。 Nothing Happens Until You subscribe()Reactor中，当你写一个Publisher链，默认情况下，数据不会启动。你要增加一个异步处理的抽象描述（帮助重用和组合）。通过订阅，把Publisher绑定到Subscriber，从而出发整个链中的数据流。在内部，Subscriber发送一个request信号，向上游传递，直到Publisher。 Backpressurebackpressure也是通过向上游传递信号实现的，还是用装配线做类比，如果工作站处理得比上游慢就发送一个反馈信号。Reactive Streams规范的定义非常接近类比：subscriber可以在unbounded模式工作，让源以最快的速度推送数据;或者使用request机制，向源发信号，它现在可以处理最多n条数据。中间operators也可以改变request。比如buffer operator，可以把数据分组。还有些operators实现了prefetching策略，这就避免了request(1)往返，如果在请求之前就生成元素不太昂贵，这样处理是划算的。这样，把push模式变成了push-pull，如果有数据，下游可以从上游pull数据。如果没有数据，就等数据准备好以后push给下游。 Hot vs Cold有两大类反应式序列hot和cold。主要区别是响应式流如何应答订阅： Cold：为每个Subscriber都生成新的序列，包括数据源。比如，如果源包装了一个HTTP调用，就为每个订阅生成一个新的HTTP请求 Hot：对于每个Subscriber，不会重新开始。相反，迟到的订阅者只能接收到订阅之后发射的数据。注意，一些hot响应式流可以缓存或者重放历史（甚至全部历史）。hot的序列甚至可以在没有订阅者时也发射数据 Reactor Core FeaturesReactor提供了可组合的响应式类型，他们（Flux和Mono）实现了Publisher，还提供了丰富的operators。Flux代表0…N个元素，Mono代表(0…1)。比如，HTTP请求只有一个响应，所以应该不会做count运算。所以，使用Mono代表一次HTTP请求的结果会更好。改变最大基数的Operators会切换相关类型。比如，Flux才有count运算，但是它返回Mono。 Flux, an Asynchronous Sequence of 0-N Items Flux是一个标准的Publisher，可以由一个completion信号或者error终止。三种类型的信号转换为对下游Subscriber的onNext、onComplete或者onError方法的调用。所有的事件，包括terminating，都是可选的。如果没有onNext事件但是有onComplete代表一个empty有限序列;而删除了onComplete，就变成一个无限的空序列（没什么用，除非要测试cancellation）。无限序列不一定是空的，比如，Flux.interval(Duration)生产的Flux就是无限的，根据时钟发出滴答声。 Mono, an Asynchronous 0-1 Result Mono 是一个专用的Publisher，最多发送一条数据，然后可以由onComplete或者onError信号终止。只包含Flux的operators的子集，一些operators可以切换到Flux。比如，Mono#concatWith(Publisher)返回一个Flux，Mono#then(Mono) 返回另一个Mono。Mono可以代表一个无值的异步处理，它仅有completion概念（类似Runnable）。想增加这样一个，请使用Mono。 Simple Ways to Create a Flux or Mono and Subscribe to It可以使用工厂方法开始使用Flux和Mono。比如，要增加一个String序列，可以枚举他们，可以放进集合，然后增加Flux： 12345Flux&lt;String&gt; seq1 = Flux.just(\"foo\", \"bar\", \"foobar\");List&lt;String&gt; iterable = Arrays.asList(\"foo\", \"bar\", \"foobar\");Flux&lt;String&gt; seq2 = Flux.fromIterable(iterable);1234 其他例子： 1234567//没有值，也可以使用泛型Mono&lt;String&gt; noData = Mono.empty(); Mono&lt;String&gt; data = Mono.just(\"foo\");//第一个参数是范围的开始，第二个参数是数量Flux&lt;Integer&gt; numbersFromFiveToSeven = Flux.range(5, 3); 123456 订阅的时候，Flux和Mono支持Java 8 lambdas。可以选择.subscribe()的变种，将lambdas用于不同的回调组合： 1234567891011121314151617//订阅，触发一个序列subscribe(); //使用每个产生的值做点啥subscribe(Consumer&lt;? super T&gt; consumer); //处理值，也响应错误subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer); //处理值和错误。当序列successfully完成时，做点啥subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer, Runnable completeConsumer); //处理值、错误和successful完成。再使用Subscription做点什么subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer, Runnable completeConsumer, Consumer&lt;? super Subscription&gt; subscriptionConsumer);12345678910111213141516 这些变种返回对subscription的引用，当你不再需要数据时，可以cancel该subscription。通过cancellation，源会停止生产值，清除它增加的资源。这种cancel和清理由Disposable接口代表。 subscribe Method Examples本节包含subscribe方法的每个签名的最小示例。先是无参方法： 12345//生产三个值Flux&lt;Integer&gt; ints = Flux.range(1, 3);//订阅ints.subscribe();1234 前面的代码没有产生可见的输出，但是它能工作。该Flux产生了三个值。如果我们提供一个lambda，可以让值可视： 1234Flux&lt;Integer&gt; ints = Flux.range(1, 3); //订阅，打印值ints.subscribe(i -&gt; System.out.println(i));123 输出是： 1234123123 为了演示下一个方法签名，我们故意引入错误： 12345678910111213//产生四个值Flux&lt;Integer&gt; ints = Flux.range(1, 4) //需要map处理不同的值 .map(i -&gt; &#123; //对于大多数值，返回该值 if (i &lt;= 3) return i; //强制产生错误 throw new RuntimeException(\"Got to 4\"); &#125;);//订阅包含了错误处理ints.subscribe(i -&gt; System.out.println(i), error -&gt; System.err.println(\"Error: \" + error));123456789101112 我们有两个lambda表达式，一个为期望的内容，一个为错误。输出是： 12345123Error: java.lang.RuntimeException: Got to 41234 subscribe的下一个签名包含completion事件的处理： 12345Flux&lt;Integer&gt; ints = Flux.range(1, 4); ints.subscribe(i -&gt; System.out.println(i), error -&gt; System.err.println(\"Error \" + error), () -&gt; System.out.println(\"Done\")); 1234 error信号和completion信号都是终止事件，彼此排斥（不可能同时得到）。要使completion消费者工作，就不能触发错误。completion回调没有输入，由一对空括号表示：它匹配Runnable接口的run方法。前面代码的输出是： 1234561234Done12345 subscribe方法的最后一个签名包含一个Consumer。可以使用Subscription做些事情：执行request(long)，或者cancel()。否则Flux会被挂起： 1234567Flux&lt;Integer&gt; ints = Flux.range(1, 4);ints.subscribe(i -&gt; System.out.println(i), error -&gt; System.err.println(\"Error \" + error), () -&gt; System.out.println(\"Done\"), //源最多发射10个元素，实际上，只发射了四个 sub -&gt; sub.request(10)); 123456 Cancelling a subscribe() with its Disposablesubscribe()的这些变种都有一个Disposable返回类型。在这里，Disposable代表订阅能被取消（通过调用dispose() 方法）。对于Flux和Mono，cancellation是一个信号，源会停止产生数据。但是，不能保证是立竿见影的。有些源生产数据的速度太快，在收到cancel指令前可能已经完成了。Disposables类中有一些实用的工具。Disposables.swap()增加一个Disposable包装器，允许你原子地cancel或者替换一个具体的Disposable。比如在一个UI场景中，每当用户按下一个button，你就可以cancel一个请求，替换成一个新的。 Alternative to lambdas: BaseSubscriber也可以扩展BaseSubscriber，实现订阅功能。比如这样调用一个SampleSubscriber： 12345678SampleSubscriber&lt;Integer&gt; ss = new SampleSubscriber&lt;Integer&gt;();Flux&lt;Integer&gt; ints = Flux.range(1, 4);ints.subscribe(i -&gt; System.out.println(i), error -&gt; System.err.println(\"Error \" + error), () -&gt; &#123;System.out.println(\"Done\");&#125;, s -&gt; s.request(10));ints.subscribe(ss);1234567 SampleSubscriber是这样实现的： 12345678910111213public class SampleSubscriber&lt;T&gt; extends BaseSubscriber&lt;T&gt; &#123; public void hookOnSubscribe(Subscription subscription) &#123; System.out.println(\"Subscribed\"); request(1); &#125; public void hookOnNext(T value) &#123; System.out.println(value); request(1); &#125;&#125;123456789101112 SampleSubscriber类扩展了BaseSubscriber，这是自定义Subscribers时，Reactor推荐扩展的抽象类。它提供了可以被覆盖的钩子，以调整subscriber的行为。默认会触发一个unbounded的请求，表现得很像subscribe()。如果你想自定义请求总量，扩展BaseSubscriber就很好。要自定义请求量，最低限度要实现hookOnSubscribe(Subscription subscription) 和hookOnNext(T value)。前面的例子，hookOnSubscribe打印到标准输出，然后发送第一次请求。hookOnNext打印值，执行附加的请求，每次一条。上面SampleSubscriber类的输出是 123456Subscribed123412345 BaseSubscriber类还包含requestUnbounded()方法，可以切换到unbounded模式（相当于request(Long.MAX_VALUE)）。此外还有cancel()方法。它还有这些钩子：hookOnComplete、hookOnError、hookOnCancel和hookFinally（总是在序列终止时被调用，终止类型见SignalType参数）。 On Backpressure, and ways to reshape requestsReactor实现背压的时候，消费者向上游operator发送request。当前请求的和有时候被称为当前demand或者是pending request。上限是Long.MAX_VALUE，代表无限的请求（没有背压）。第一个请求来自最终的subscriber。在订阅的时候，最直接的办法是触发无限的请求： subscribe()和大多数变种 block()、blockFirst()和blockLast() 使用toIterable()/toStream()迭代 自定义原始请求的最简单的办法是覆盖BaseSubscriber的hookOnSubscribe方法： 12345678910111213141516Flux.range(1, 10) .doOnRequest(r -&gt; System.out.println(\"request of \" + r)) .subscribe(new BaseSubscriber&lt;Integer&gt;() &#123; @Override public void hookOnSubscribe(Subscription subscription) &#123; request(1); &#125; @Override public void hookOnNext(Integer integer) &#123; System.out.println(\"Cancelling after having received \" + integer); cancel(); &#125; &#125;);123456789101112131415 输出是 123request of 1Cancelling after having received 112 操纵request的时候，你必须小心地产生足够的序列要求，否则你的Flux会被卡住。所以，BaseSubscriber的hookOnSubscribe默认是无限的request。如果你覆盖这个钩子，最少要调用一次request。 Operators changing the demand from downstream要记住，subscribe级别的要求，能被上游的每个operator重新整形。比如buffer(N) operator：如果它收到request(2)，它解释成需要two full buffers。因为buffers认为有N个元素就是满的，该buffer operator使得request成了2 x N。 Prefetch是在内部序列调整初始request的方法，一般来说，默认是32。这些operators一般也实现了补充（replenishing）优化：一旦operator看到25%的prefetch已经完成，就再向上游请求25%。这是一种启发式的优化，让这些operators主动预测即将到来的请求。 也可以直接调整request：limitRate和limitRequest。limitRate(N)拆分下游请求，让他们以较小的批量传播到上游。比如一个100的request，通过limitRate(10)会导致最多10次10个的requests，传播到上游。limitRate实现了上面讨论的补充优化。该operator有个变种，可以调整补充总量：limitRate(highTide, lowTide)，lowTide为0就是严格的highTide批量的请求，而没有补充优化。limitRequest(N)定义下游request的最大总需求。如果单个request不会让总需求超过N，整个request就会传给上游。达到总量，limitRequest认为序列完成，向下游发射onComplete并cancel资源。 Reactor Core FeaturesProgrammatically creating a sequence本节介绍如何程序化增加Flux和Mono，以及相关事件（onNext、onError和onComplete）。这些方法都触发了称为sink的事件。实际上是sink的变种。 Synchronous generate程序化增加Flux的最简单办法是generate方法，接受一个generator 函数。它是同步的，one-by-one 地发射。这是一个SynchronousSink，每次回调最多只能调用一次next()方法。之后可以调用error(Throwable)和complete(),他们是可选的。最有用的变种可能是：让你保持state，还可以引用sink，决定下一个发射什么。该generator函数变成了BiFunction&lt;S, SynchronousSink&lt; T &gt;, S&gt;，其中&lt; S &gt;就是state对象。你可以为初始state提供一个Supplier&lt; S &gt;，你的generator 函数在每一轮都能返回一个新state。比如，使用int做state： 123456789101112Flux&lt;String&gt; flux = Flux.generate( //初始state是0 () -&gt; 0, (state, sink) -&gt; &#123; //根据state选择发射的内容 sink.next(\"3 x \" + state + \" = \" + 3*state); //完成 if (state == 10) sink.complete(); //新的state return state + 1; &#125;);1234567891011 上面代码的输出是 1234567891011123 x 0 &#x3D; 03 x 1 &#x3D; 33 x 2 &#x3D; 63 x 3 &#x3D; 93 x 4 &#x3D; 123 x 5 &#x3D; 153 x 6 &#x3D; 183 x 7 &#x3D; 213 x 8 &#x3D; 243 x 9 &#x3D; 273 x 10 &#x3D; 301234567891011 也可以使用可变的。比如下面的代码，使用AtomicLong做state： 123456789101112Flux&lt;String&gt; flux = Flux.generate( //state可变 AtomicLong::new, (state, sink) -&gt; &#123; //改变了state long i = state.getAndIncrement(); sink.next(\"3 x \" + i + \" = \" + 3*i); if (i == 10) sink.complete(); 返回新state的同一个实例 return state; &#125;);1234567891011 如果state需要清理资源。可以使用generate(Supplier, BiFunction, Consumer)清理最后一个state实例。下面的例子就包含了一个Consumer： 1234567891011Flux&lt;String&gt; flux = Flux.generate( AtomicLong::new, (state, sink) -&gt; &#123; long i = state.getAndIncrement(); sink.next(\"3 x \" + i + \" = \" + 3*i); if (i == 10) sink.complete(); return state; //最后输出11 &#125;, (state) -&gt; System.out.println(\"state: \" + state)); &#125;12345678910 如果该state包含数据库连接，或者其他需要处理的资源。该Consumer表达式可以关闭连接或者其他处理。 Asynchronous &amp; multi-threaded: createcreate比较先进，支持每轮多个发射，甚至支持多线程。它暴露了一个FluxSink，有next、error和complete方法。和generate不同，它没有基于state的变种。在回调中，能触发多线程事件。create可以把现有API带入响应式世界，比如基于监听器的异步API。create不会并行化你的代码，也不会把代码变成异步的。即使使用subscribeOn，也要注意：长时间阻塞create lambda（比如无限循环地调用sink.next(t)）会锁定管道。请求可能永远不会被执行。使用subscribeOn(Scheduler, false) 变种，requestOnSeparateThread = false，create使用Scheduler线程，数据流执行请求也使用同样的线程。 想像你使用listener-based API。它通过chunks处理事件，有两个事件：(1) 数据准备好，(2) 处理完成（terminal事件）。如MyEventListener接口所示： 12345interface MyEventListener&lt;T&gt; &#123; void onDataChunk(List&lt;T&gt; chunk); void processComplete();&#125;1234 你可以create一个bridge，放进Flux： 12345678910111213141516171819Flux&lt;String&gt; bridge = Flux.create(sink -&gt; &#123; //每当myEventProcessor执行时，他们异步执行 myEventProcessor.register( new MyEventListener&lt;String&gt;() &#123; public void onDataChunk(List&lt;String&gt; chunk) &#123; for(String s : chunk) &#123; //chunk中的每个元素，成为Flux中的元素 sink.next(s); &#125; &#125; public void processComplete() &#123; //processComplete事件转换成onComplete sink.complete(); &#125; &#125;);&#125;);123456789101112131415161718 另外，因为create能bridge异步API，管理背压，你可以通过OverflowStrategy，来优化背压： IGNORE：完全忽略下游的背压请求。当下游队列满时，可能产生IllegalStateException ERROR：下游跟不上时，IllegalStateException DROP：下游没准备好接收，就抛弃输入信号 LATEST：下游只读取最新信号 BUFFER（默认）：下游忙不过来就缓冲信号（无限的buffer，可能导致OutOfMemoryError） Mono也有create generator。MonoSink不允许多个发射。在第一个之后drop全部信号。 Asynchronous but single-threaded: pushpush位于generate和create之间，适合处理单个生产者的事件。和create类似，它支持异步，也可以像create那样管理背压。但是，在某一时刻，只能有一个生产者线程调用next、complete和error。 1234567891011121314151617181920212223Flux&lt;String&gt; bridge = Flux.push(sink -&gt; &#123; myEventProcessor.register( new SingleThreadEventListener&lt;String&gt;() &#123; public void onDataChunk(List&lt;String&gt; chunk) &#123; for(String s : chunk) &#123; /使用next，从单个监听器线程推送数据给sink sink.next(s); &#125; &#125; public void processComplete() &#123; //complete事件由同一个监听器线程生成 sink.complete(); &#125; public void processError(Throwable e) &#123; //error事件也由同一个监听器线程生成 sink.error(e); &#125; &#125;);&#125;);12345678910111213141516171819202122 An hybrid push/pull model大多数Reactor operators，比如create，遵循混合push/pull 模式。尽管大部分处理是异步的（建议使用push方式），但是也有pull组件-request。消费者从源pulls数据，在第一次请求之前不会发射任何数据。然后，只要数据准备好，源就把数据推给消费者，不过要在请求总量范围内。push() 和create()都允许设置一个onRequest消费者，以便管理请求总量、并确保只有在他们等候请求的时候才通过sink推送数据。 123456789101112131415161718192021Flux&lt;String&gt; bridge = Flux.create(sink -&gt; &#123; myMessageProcessor.register( new MyMessageListener&lt;String&gt;() &#123; public void onMessage(List&lt;String&gt; messages) &#123; for(String s : messages) &#123; //之后异步到达的其余消息也被交付 sink.next(s); &#125; &#125; &#125;); sink.onRequest(n -&gt; &#123; //请求之后拉消息 List&lt;String&gt; messages = myMessageProcessor.getHistory(n); for(String s : message) &#123; //如果消息有效，就推给sink sink.next(s); &#125; &#125;);&#125;);1234567891011121314151617181920 Cleaning up after push() or create()两个回调，onDispose和onCancel，在终止或者取消的时候执行清理。onDispose在Flux完成、错误退出或者取消后执行。onCancel在onDispose执行之前执行任何取消动作。 12345678Flux&lt;String&gt; bridge = Flux.create(sink -&gt; &#123; sink.onRequest(n -&gt; channel.poll(n)) //onCancel先被调用，仅适用cancel信号 .onCancel(() -&gt; channel.cancel()) //onDispose被调用，适用complete、error或者cancel信号 .onDispose(() -&gt; channel.close()) &#125;);1234567 Handlehandle方法有很大的不同。它是一个实例方法，它是链式的只能在已经存在的源上。支持Mono和Flux。它接近generate，从某种意义上说，它使用了SynchronousSink，只能一个接一个地发射。不过，handle可以从每个源生成任意值，可能会跳过一些元素。可以当作map和filter的组合。它的签名是： 12Flux&lt;R&gt; handle(BiConsumer&lt;T, SynchronousSink&lt;R&gt;&gt;);1 下来看一个例子，响应式流规范里序列不能有null值。如果你想执行一个map，但是你想使用已经存在的方法做map操作，该方法有时候返回null。比如下面的方法可以安全地用于整数源： 12345678public String alphabet(int letterNumber) &#123; if (letterNumber &lt; 1 || letterNumber &gt; 26) &#123; return null; &#125; int letterIndexAscii = 'A' + letterNumber - 1; return \"\" + (char) letterIndexAscii;&#125;1234567 我们可以使用handle删除任何null： 1234567891011Flux&lt;String&gt; alphabet = Flux.just(-1, 30, 13, 9, 20) .handle((i, sink) -&gt; &#123; //映射成字符串 String letter = alphabet(i); if (letter != null) //如果返回null，不调用sink.next sink.next(letter); &#125;);alphabet.subscribe(System.out::println);12345678910 程序的输出是 1234MIT123 Threading and SchedulersReactor是并发不可知论者（concurrency agnostic），它不会强制并发模型。获取Flux或者Mono不意味着它在专用的线程中运行。大多数operators 会在前一个operator工作的线程中执行。如果不指定，源在subscribe() 调用的线程中运行。 1234567891011121314public static void main(String[] args) &#123; //Mono&lt;String&gt;在main线程中组装 final Mono&lt;String&gt; mono = Mono.just(\"hello \"); new Thread(() -&gt; mono .map(msg -&gt; msg + \"thread \") .subscribe(v -&gt; //在Thread-0订阅，于是，map和onNext回调也在该线程中执行 System.out.println(v + Thread.currentThread().getName()) ) ).join();&#125;12345678910111213 程序的输出是 12hello thread Thread-01 Reactor中，执行模型和在哪儿执行由使用的Scheduler决定。Scheduler的调度职责类似于ExecutorService，不过作为时钟，做了更多。Schedulers类的静态方法可以访问执行上下文： immediate() - 当前线程 single() - 单个、可重用线程。注意，该方法会为所有调用者重用同一个线程，知道它被disposed。如果你想为每个调用生成专有的线程，使用newSingle()方法 elastic() - 一个弹性线程池。按需增加工作线程池，重用空闲的。线程持续空闲太久（默认60秒），会被disposed。I/O阻塞工作可以使用该方法 parallel() - 固定大小的线程池：CPU核数 也可以使用Schedulers.fromExecutorService(ExecutorService)方法，从已经存在的ExecutorService增加Scheduler。（也可以从Executor增加）如果阻塞无法避免，可以使用elastic帮助遗留的阻塞代码，single和parallel不行。所以，如果在默认的single和parallel的Schedulers内使用Reactor的阻塞API（block()、blockFirst()和blockLast()，还有迭代的toIterable()和toStream()），会抛IllegalStateException。通过创建实现了NonBlocking标记接口的Thread的实例，也能自定义“仅非阻塞”的Schedulers。 一些operators默认使用特定的Scheduler（你也可以使用不同的）。比如，Flux.interval(Duration.ofMillis(300)) 产生的Flux，默认使用Schedulers.parallel()。你也可以这样写： 123//使用不同的SchedulerFlux.interval(Duration.ofMillis(300), Schedulers.newSingle(\"test\"))12 Reactor提供了两种在响应式链中切换执行上下文（Scheduler）的方法：publishOn和subscribeOn。都接受Scheduler参数，来切换上下文。但是，在链中publishOn的位置很重要，而subscribeOn的位置却不重要。当你链式operators的时候，可以包装很多Flux和Mono。一旦你subscribe了，Subscriber对象的链就生成了，一直回到源。当然你看不到，你能看到的外层的Flux（Mono）和Subscription，但是，实际工作发生在这些中间operator的订阅者那里。有了这些知识，我们仔细看看publishOn和subscribeOn： publishOnpublishOn跟其他operator一样，在订阅链的中间。从上游接收信号，下游的operators在相关Scheduler的线程上执行。 从Scheduler选择线程，改变执行上下文 onNext使用同一个线程，按顺序执行 或者在特定的Scheduler上工作，或者publishOn之后的operators在相同线程上执行 123456789101112131415//新Scheduler，包含4个线程Scheduler s = Schedulers.newParallel(\"parallel-scheduler\", 4); final Flux&lt;String&gt; flux = Flux .range(1, 2) //第一个map在匿名线程上执行 .map(i -&gt; 10 + i) //切换到s包含的线程 .publishOn(s) //第二个map在s的线程上执行 .map(i -&gt; \"value \" + i); //订阅使用了这个匿名线程。print发生在s包含的线程new Thread(() -&gt; flux.subscribe(System.out::println));1234567891011121314 subscribeOn当构造后向的链时，subscribeOn用于subscription处理。不管你在链的任何位置写subscribeOn，它都影响源的上下文。它不影响调用了publishOn的子序列的上下文。 改变订阅之上整个链的operators的线程 从Scheduler挑一个线程 链中最早的subscribeOn有效。 1234567891011121314//新Scheduler，包含4个线程Scheduler s = Schedulers.newParallel(\"parallel-scheduler\", 4); final Flux&lt;String&gt; flux = Flux .range(1, 2) //第一个map在s的线程上执行 .map(i -&gt; 10 + i) //因为subscribeOn，从订阅开始切换序列 .subscribeOn(s) //和第一个map的执行线程相同 .map(i -&gt; \"value \" + i); //订阅初始化时使用匿名线程。然后马上切换到s的线程new Thread(() -&gt; flux.subscribe(System.out::println)); 12345678910111213 Handling Errors响应式系统中，错误是结束事件。当错误发生的时候，它停止序列，传播到链的最后一步，定义的Subscriber的onError方法。此类错误应该由程序处理。比如，显示错误提示，或者发送有意义的错误信息。因此，应该定义onError方法。如果没定义，抛出UnsupportedOperationException。你可以做进一步检测，使用Exceptions.isErrorCallbackNotImplemented方法分流。 Reactor也支持在链的中间处理错误，这就是错误operators。 123456Flux.just(1, 2, 0)//i等于0时抛异常 .map(i -&gt; \"100 / \" + i + \" = \" + (100 / i)) //错误处理 .onErrorReturn(\"Divided by zero :(\"); 12345 在你学习错误处理operators前，必须记住，错误是序列的结束事件。甚至你使用了错误处理operator，也不会允许原始（original）序列继续。onError信号会作为新序列的开头（回退） Error Handling Operators你可能熟悉使用try-catch处理异常： Catch，返回静态默认值 Catch，使用回退（fallback）方法执行其他路径 Catch，动态计算fallback值 Catch，包装成一个BusinessException，重新抛出 Catch，记录错误信息，重新抛出 使用finally块或者try-with-resource清理资源 所有的这些，在Reactor中都有等价物，有对应的错误处理operators。 123456789Flux&lt;String&gt; s = Flux.range(1, 10)//会泡异常 .map(v -&gt; doSomethingDangerous(v)) //如果一切正常，会执行 .map(v -&gt; doSecondTransform(v));s.subscribe(value -&gt; System.out.println(\"RECEIVED \" + value), //如果没失败，成功打印 error -&gt; System.err.println(\"CAUGHT \" + error) //如果有错误，序列种植，打印失败信息);12345678 和下面的代码类似： 12345678910111213try &#123; for (int i = 1; i &lt; 11; i++) &#123; //如果错误就抛异常 String v1 = doSomethingDangerous(i); //正确就执行 String v2 = doSecondTransform(v1); System.out.println(\"RECEIVED \" + v2); &#125;&#125; catch (Throwable t) &#123; //异常就跳转到这里 System.err.println(\"CAUGHT \" + t); &#125;123456789101112 Static Fallback Value返回静态默认值，相当于onErrorReturn： 1234567try &#123; return doSomethingDangerous(10);&#125;catch (Throwable error) &#123; return \"RECOVERED\";&#125;123456 变成了： 1234Flux.just(10) .map(this::doSomethingDangerous) .onErrorReturn(\"RECOVERED\");123 也可以使用任选的Predicate： 12345Flux.just(10) .map(this::doSomethingDangerous) //只有在异常消息是boom10的时候，才返回 .onErrorReturn(e -&gt; e.getMessage().equals(\"boom10\"), \"recovered10\"); 1234 Fallback Method如果不想简单返回默认值，而是有其他的处理数据的路径，可以使用onErrorResume： 12345678910111213141516String v1;try &#123; v1 = callExternalService(\"key1\");&#125;catch (Throwable error) &#123; v1 = getFromCache(\"key1\");&#125;String v2;try &#123; v2 = callExternalService(\"key2\");&#125;catch (Throwable error) &#123; v2 = getFromCache(\"key2\");&#125;123456789101112131415 变成了 1234567Flux.just(\"key1\", \"key2\")//对于每个key，异步调用外部服务 .flatMap(k -&gt; callExternalService(k) //如果调用失败，返回缓存值 .onErrorResume(e -&gt; getFromCache(k)) );123456 onErrorResume也有Predicate变种： 123456789101112Flux.just(\"timeout1\", \"unknown\", \"key2\") .flatMap(k -&gt; callExternalService(k) .onErrorResume(error -&gt; &#123; //动态选择 if (error instanceof TimeoutException) //超时 return getFromCache(k); else if (error instanceof UnknownKeyException) //不知道的key return registerNewEntry(k, \"DEFAULT\"); else return Flux.error(error); //重新抛出异常 &#125;) );1234567891011 Dynamic Fallback Value也可以根据异常，计算fallback值。比如，你返回的MyWrapper类型，专门有一个保存了异常的变种（想一下Future.complete(T success)和Future.completeExceptionally(Throwable error)）。 12345678try &#123; Value v = erroringMethod(); return MyWrapper.fromValue(v);&#125;catch (Throwable error) &#123; return MyWrapper.fromError(error);&#125;1234567 如果使用onErrorResume，可以这样写： 12345erroringFlux.onErrorResume(error -&gt; Mono.just( //需要计算异常中的值 MyWrapper.fromError(error) ));1234 Catch and Rethrow比如 1234567try &#123; return callExternalService(k);&#125;catch (Throwable error) &#123; throw new BusinessException(\"oops, SLA exceeded\", error);&#125;123456 可以写成 123456Flux.just(\"timeout1\") .flatMap(k -&gt; callExternalService(k)) .onErrorResume(original -&gt; Flux.error( new BusinessException(\"oops, SLA exceeded\", original)) );12345 也可以这样 1234Flux.just(\"timeout1\") .flatMap(k -&gt; callExternalService(k)) .onErrorMap(original -&gt; new BusinessException(\"oops, SLA exceeded\", original));123 Log or React on the Side如果你希望错误继续传播，不修改序列，只是记录它，可以使用doOnError。 123456789try &#123; return callExternalService(k);&#125;catch (RuntimeException error) &#123; //记录日志 log(\"uh oh, falling back, service failed for key \" + k); throw error;&#125;12345678 该doOnError，和前面的其他以doOn为前缀的operators一样，有时候被称为“副作用”。可以用来在不修改序列事件的情况下查看他们。下面的例子还会传播错误，但是我们记录下来了。我们甚至使用了错误统计计数器。 1234567891011LongAdder failureStat = new LongAdder();Flux&lt;String&gt; flux =Flux.just(\"unknown\") .flatMap(k -&gt; callExternalService(k) //调用失败 .doOnError(e -&gt; &#123; failureStat.increment(); log(\"uh oh, falling back, service failed for key \" + k); //日志+统计 &#125;) //仍然会因为错误而终止，除非我们在这里使用error-recovery operator );12345678910 Using Resources and the Finally Block对于 123456789Stats stats = new Stats();stats.startTimer();try &#123; doSomethingDangerous();&#125;finally &#123; stats.stopTimerAndRecordTiming();&#125;12345678 和 1234try (SomeAutoCloseable disposableInstance = new SomeAutoCloseable()) &#123; return disposableInstance.toString();&#125;123 分别对应doFinally和using。 不管序列终止（onComplete、onError）或者被取消，都会执行doFinally。你可以知道结束类型： 12345678910111213Stats stats = new Stats();LongAdder statsCancel = new LongAdder();Flux&lt;String&gt; flux =Flux.just(\"foo\", \"bar\") .doOnSubscribe(s -&gt; stats.startTimer()) .doFinally(type -&gt; &#123; //结束类型SignalType stats.stopTimerAndRecordTiming(); if (type == SignalType.CANCEL) //如果是取消，就统计 statsCancel.increment(); &#125;) .take(1);//发射一个元素就取消123456789101112 using用于Flux派生自资源的情况，而且处理完成必须处置资源。让我们使用Disposable替换try-with-resource的AutoCloseable接口： 12345678910111213AtomicBoolean isDisposed = new AtomicBoolean();Disposable disposableInstance = new Disposable() &#123; @Override public void dispose() &#123; isDisposed.set(true); &#125; @Override public String toString() &#123; return \"DISPOSABLE\"; &#125;&#125;;123456789101112 我们这样使用using()： 1234567Flux&lt;String&gt; flux =Flux.using( () -&gt; disposableInstance, //生成资源，返回我们的Disposable disposable -&gt; Flux.just(disposable.toString()), //处理资源，返回Flux&lt;T&gt; Disposable::dispose //当前面的Flux结束，清理资源);123456 订阅、执行完该序列后，isDisposed变成了true。 Demonstrating the Terminal Aspect of onError为了证明，发生错误的时候，这些operators导致上游的原始序列结束，看下面使用Flux.interval的例子。 1234567891011Flux&lt;String&gt; flux =Flux.interval(Duration.ofMillis(250)) .map(input -&gt; &#123; if (input &lt; 3) return \"tick \" + input; throw new RuntimeException(\"boom\"); &#125;) .onErrorReturn(\"Uh oh\");flux.subscribe(System.out::println);Thread.sleep(2100);12345678910 程序每250毫秒打印一行，输出是 12345tick 0tick 1tick 2Uh oh1234 Retrying关于错误处理，还有一个有趣的operator：retry。它会重新订阅上游的Flux。这实际上是一个不同的序列，源已经结束了。 1234567891011Flux.interval(Duration.ofMillis(250)) .map(input -&gt; &#123; if (input &lt; 3) return \"tick \" + input; throw new RuntimeException(\"boom\"); &#125;) .retry(1) .elapsed() //把每个值和上一个值发射以后持续的时间相关联 .subscribe(System.out::println, System.err::println); Thread.sleep(2100);12345678910 程序的输出是 12345678259,tick 0249,tick 1251,tick 2506,tick 0 &#x2F;&#x2F;新的interval，从0开始248,tick 1253,tick 2java.lang.RuntimeException: boom1234567 可以看到，retry(1)只重新订阅了一次interval。在第二次，因为还出错，所以错误被传播到下游，序列结束了。还有更先进的retry版本（retryWhen），使用一个伙伴Flux，判断特定的错误是否应该重试。这个伙伴Flux由用户装饰（decorated），自定义retry条件。伙伴Flux是一个Flux，传的参数是Function，返回Publisher&lt;?&gt;。retry这样工作： 错误发生，被传给伙伴Flux 如果伙伴Flux发射一个值，retry发生 如果伙伴Flux完成，retry结束，序列完成 如果伙伴Flux抛异常e，retry结束，序列抛e 12345Flux&lt;String&gt; flux = Flux .&lt;String&gt;error(new IllegalArgumentException()) .doOnError(System.out::println) .retryWhen(companion -&gt; companion.take(3)); //重试3次1234 上面的程序的结果是一个empty Flux，但是它successfully完成了。因为相同Flux上的retry(3) 以最后的错误结束，这个retryWhen例子和retry(3)不完全一样。想达到相同的效果，需要一些技巧： 12345678910Flux&lt;String&gt; flux =Flux.&lt;String&gt;error(new IllegalArgumentException()) .retryWhen(companion -&gt; companion .zipWith(Flux.range(1, 4), (error, index) -&gt; &#123; if (index &lt; 4) return index; else throw Exceptions.propagate(error); &#125;) );123456789 Handling Exceptions in Operators or Functions通常，所有的operators自身就包含可能抛异常的代码，调用的用户代码也可能产生类似的失败，所以，都包含失败处理。根据经验，Unchecked Exception总是通过onError传播。比如，在一个map函数内部抛RuntimeException会转换成一个onError事件: 12345Flux.just(\"foo\") .map(s -&gt; &#123; throw new IllegalArgumentException(s); &#125;) .subscribe(v -&gt; System.out.println(\"GOT VALUE\"), e -&gt; System.out.println(\"ERROR: \" + e));1234 上面代码的输出是 12ERROR: java.lang.IllegalArgumentException: foo1 Reactor定义了一个异常集合（比如OutOfMemoryError），认为他们是fatal，见Exceptions.throwIfFatal方法。这些错误意味着Reactor不能继续运行，会被抛出。在内部，也存在unchecked exception不能被传播的情况（尤其在订阅和请求阶段），由于并发竞争（concurrency races）可能同时满足onError和onComplete条件。当这些竞争发生的时候，错误可能不能传播给dropped。不过，仍然可以通过定制钩子（hook）做一定程度的管理。 你可能会问，那Checked Exceptions呢？比如，你调用了申明了会抛异常的方法，还是应该使用try-catch块处理异常。你有几种选择： 捕获异常，从中恢复。sequence继续 捕获异常，包装成unchecked异常，然后抛出（中断sequence）。Exceptions类会为你提供帮助 如果希望返回Flux（比如使用flatMap），可以把异常包装到错误生成中Flux::return Flux.error(checkedException)（序列终止） Reactor提供了Exceptions类，你可以使用它，确保只包装checked异常： 必要的时候，使用Exceptions.propagate包装异常。它首先调用throwIfFatal，不会包装RuntimeException 使用Exceptions.unwrap得到未包装的原始异常 比如，下面的方法会抛IOException： 1234567public String convert(int i) throws IOException &#123; if (i &gt; 3) &#123; throw new IOException(\"boom \" + i); &#125; return \"OK \" + i;&#125;123456 现在，你想在map中调用该方法。你必须捕获该异常，而且map函数不能再次抛出它，你可以这样： 1234567Flux&lt;String&gt; converted = Flux .range(1, 10) .map(i -&gt; &#123; try &#123; return convert(i); &#125; catch (IOException e) &#123; throw Exceptions.propagate(e); &#125; &#125;);123456 然后，在订阅的时候，可以得到原始异常： 1234567891011converted.subscribe( v -&gt; System.out.println(\"RECEIVED: \" + v), e -&gt; &#123; if (Exceptions.unwrap(e) instanceof IOException) &#123; System.out.println(\"Something bad happened with I/O\"); &#125; else &#123; System.out.println(\"Something bad happened\"); &#125; &#125;);12345678910 ProcessorsProcessors是特殊的Publisher，而且也是Subscriber。这就是说，你可以subscribe一个Processor（通常，实现了Flux），你也可以调用方法手工注入数据，或者终止它。有几种类型的Processors，每个都有特殊的语义，在你研究之前，应该问自己几个问题： Do I Need a Processor?应该尽量避免使用Processor，他们不容易正确使用，一般用于特殊场合。如果你认为Processor很适合，就问一下自己，是否尝试过下面两个选择： operator，或者他们的组合是否符合要求 是否可以用 “generator” operator 代替（通常，他们是桥梁API，不是响应式的。提供的sink可以手工填充sequence或者终止它） Safely Produce from Multiple Threads by Using the Sink Facade和直接使用Processors相比，更好的办法是调用sink() 方法获取Sink。FluxProcessor的Sink是多线程producers。比如，对于UnicastProcessor： 123UnicastProcessor&lt;Integer&gt; processor = UnicastProcessor.create();FluxSink&lt;Integer&gt; sink = processor.sink(overflowStrategy);12 之后，多个生产者线程可以使用sink并发生成数据： 12sink.next(n);1 next方法可能溢出，这由Processor的配置决定： 无边界的Processor，自己通过dropping或者buffering处理溢出 有边界的Processor，对于IGNORE策略会阻塞或者旋转（spins），或者定制overflowStrategy Overview of Available ProcessorsReactor自带的Processor大致可分为几类： direct (DirectProcessor、UnicastProcessor)：只能使用Sink提供数据 synchronous (EmitterProcessor、ReplayProcessor)：通过用户交互推送数据，或者通过上游Publisher同步排泄 asynchronous (WorkQueueProcessor、TopicProcessor)：数据来自用户交互，或者多个上游Publishers。他们更强大，有RingBuffer支持 异步的最复杂，有许多选项。所以，暴露了Builder接口。而其他简单的只有静态工厂方法。 Direct ProcessorDirect Processor可以把信号派发给0个或者多个Subscribers。它不能处理背压。如果最少有一个订阅者请求量少于N，而你推送了N条数据，DirectProcessor就发射IllegalStateException。一旦Processor终止了（一般通过调用它的sink的error(Throwable)或者complete()方法），它允许更多订阅者订阅，但是会立刻重播termination信号。 Unicast Processor有内部buffer，可以处理背压。但是，最多只能有一个Subscriber。UnicastProcessor有几个选项，所以有多个工厂方法。比如默认的是unbounded，如果Subscriber还没请求数据，不管你给它多少数据，都会被缓存。也可以使用自定义的Queue，如果该队列是有边界的，processor可以拒绝推送数据。也可以定义一个回调，当队列满了就调用该回调。 Emitter ProcessorEmitter Processor 能够发射给几个订阅者，并尊重每个订阅者的背压。它还可以订阅一个Publisher，同步地中继它的信号。还没有订阅的时候，根据可配置的bufferSize，它只能接受很少的数据。如果还没有Subscriber消费数据，onNext被阻塞。第一个订阅者会收到这些缓存的数据。它不会为后来的订阅者重播数据，后来的订阅者只能收到以后的新数据。默认地。如果全部订阅者都cancelled，它会清除内部缓存，停止接受新的订阅者。可以通过autoCancel参数修改该行为。 Replay Processor它缓存数据。或者通过 sink()，或者通过上游Publisher。会为后来的订阅者重播数据。有几种配置： 缓存单个元素（cacheLast） 缓存有限的（create(int)），或者无限的（create()） 缓存基于时间的重播窗口（createTimeout(Duration)） 大小和时间的组合（createSizeOrTimeout(int, Duration)） Topic Processor异步的。当使用shared配置（builder()的share(boolean)选项）生成的时候，可以中继多个上游Publishers。如果你打算并发调用TopicProcessor的onNext、onComplete或者onError方法，或者来自并发的上游Publisher，会强制使用share选项。它可以有多个Subscribers。它会为每个Subscriber关联一个线程，它会一直运行，知道产生onError或者onComplete信号，或者订阅被取消。订阅者的数量由executor选项决定。它包含RingBuffer，存储推送的信号。Subscriber线程会保存RingBuffer的指针。还有autoCancel选项，默认是true，如果源被cancelled，所有的订阅也都被cancelled。 WorkQueue Processor异步的。当使用shared配置（builder()的share(boolean)选项）生成的时候，可以中继多个上游Publishers。它不完全遵循Reactive Streams规范，所以比TopicProcessor节省资源。它也基于RingBuffer，但是不会为每个订阅者增加线程。所以，它比TopicProcessor容易扩展。来自每个订阅者的请求被集中到一起，被中继的信号只发送给一个Subscriber，采用round-robin模式。它的选项和TopicProcessor相同。它不应该有太多的订阅者。否则可能lock该Processor。 有专属的测试包： 123456&lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;12345 主要包括： StepVerifier - 一步一步地测试序列 TestPublisher - 生产数据，测试下游operators的行为 可选Publisher的序列中（比如使用了switchIfEmpty），确保使用某一个 Testing a Scenario with StepVerifier可以一步一步地定义一个测试场景：下一个事件是什么？希望Flux发射一个特定值？或者接下来的300ms什么都不做？他们都可以通过StepVerifier实现。比如下面的Flux装饰代码： 1234public &lt;T&gt; Flux&lt;T&gt; appendBoomError(Flux&lt;T&gt; source) &#123; return source.concatWith(Mono.error(new IllegalArgumentException(\"boom\")));&#125;123 为了测试，你想这样验证：首先发射foo，然后发射bar，然后是产生错误消息boom。使用StepVerifier，测试代码如下： 12345678910111213@Testpublic void testAppendBoomError() &#123; //需要一个源Flux Flux&lt;String&gt; source = Flux.just(\"foo\", \"bar\"); StepVerifier.create( //增加StepVerifier builder appendBoomError(source)) .expectNext(\"foo\") //第一个信号是onNext，值是foo .expectNext(\"bar\") .expectErrorMessage(\"boom\") //最后一个信号是onError，包含一个boom消息 .verify(); //触发测试&#125;123456789101112 该API是一个builder。通过增加StepVerifier，把序列传给它来做测试。它提供了下列方法： 表达式expectations是关于下一个信号的。如果收到其他信号（或者内容不匹配），测试失败，并带有有意义的AssertionError。比如你可以使用expectNext(T…) ，或者expectNextCount(long) Consume下一个信号。当你想跳过部分序列，或者想为信号内容使用自定义的assertion的时候（比如，想检查onNext事件，并且发射了包含5条数据的列表）。比如你可以使用consumeNextWith(Consumer) 其他操作，比如暂停或者运行任意代码。比如，如果想操纵某上下文或者状态，可能会使用thenAwait(Duration)和then(Runnable) 对于终止事件，相应的expectation方法是expectComplete()和expectError()的变种。最后，你能做些附加配置，然后触发验证，一般是使用verify()或者变种。如果验证失败，抛出AssertionError。 Better identifying test failures as(String)：可用于大多数expect*的后面，描述前面的expectation。如果失败，错误消息包含该描述。终止expectations和verify不能被描述 StepVerifierOptions.create().scenarioName(String)：使用StepVerifierOptions增加StepVerifier，可以使用scenarioName给整个场景命名。它也会在错误消息中使用 注意，只有在产生自己的AssertionError的StepVerifier方法，会在消息中使用description/name。 Manipulating Time基于时间的operators，可以使用StepVerifier.withVirtualTime。以避免测试长时间运行。比如： 123StepVerifier.withVirtualTime(() -&gt; Mono.delay(Duration.ofDays(1)))//... continue expectations here12 虚拟时间特性，在Schedulers工厂中加入一个定制Scheduler。由于时间operators默认使用Schedulers.parallel()，现在替换成了VirtualTimeScheduler。重要的是：在虚拟时间调度器激活之后，再实例化该operator。为提高成功率，该StepVerifier的输入不是简单的Flux，而是Supplier。这样会延迟生成要测试的flux的实例。一定要确保Supplier&lt;Publisher&lt; T &gt;&gt;的延迟性。该Flux的实例化应该在lambda内。 有两个和时间相关的expectation，不管是否使用虚拟时间都有效： thenAwait(Duration)：暂停评估步骤 expectNoEvent(Duration)：序列可以继续，如果给定时间内有事件，就失败 这两个方法在经典方式下会将线程暂停一些时间，在虚拟时间方式下也会改进虚拟时钟。expectNoEvent会认为subscription也是一个事件。如果在第一步使用了它，一般会失败，这是因为检测到了subscription信号。此时，可以使用expectSubscription().expectNoEvent(duration)。 为了快速评估Mono.delay的行为，可以这样写代码： 123456StepVerifier.withVirtualTime(() -&gt; Mono.delay(Duration.ofDays(1))) .expectSubscription() .expectNoEvent(Duration.ofDays(1)) //1天内什么都没发生 .expectNext(0L) //然后发射0 .verifyComplete(); //完成12345 Performing Post-execution Assertions with StepVerifier在最后一个expectation之后，如果想使用assertion API ，而不是触发 verify()。可以使用verifyThenAssertThat()。它返回StepVerifier.Assertions 对象。这样，在场景胜利结束后，可以断言一些状态元素。 Testing the Context对于上下文的传播，有一些expectations： expectAccessibleContext：返回一个ContextExpectations，用来设置expectations 。确保调用then()以返回sequence expectations的设置 expectNoAccessibleContext：希望测试operators链上，不传播上下文 可以使用StepVerifierOptions，给StepVerifier关联一个测试初始上下文。代码： 12345678StepVerifier.create(Mono.just(1).map(i -&gt; i + 10), StepVerifierOptions.create().withInitialContext(Context.of(\"foo\", \"bar\"))) //有初始Context .expectAccessibleContext() //上下文传播expectations .contains(\"foo\", \"bar\") //上下文中，key foo的值是bar .then() //切换回正常expectations .expectNext(11) .verifyComplete();//结束 1234567 Manually Emitting with TestPublisher对于更高级的测试用例，可能需要完全掌握数据源，以便触发想要的信号。或者你实现了自己的operator，想验证是否满足Reactive Streams规范。 对此，提供了TestPublisher类。它是Publisher ，可以用程序触发以下信号： next(T)、next(T, T…)：触发1-n个onNext信号 emit(T…) ：发射数据，然后complete() complete() ：使用onComplete信号结束 error(Throwable)：使用onError信号结束 可以通过create工厂方法获得TestPublisher。也可以使用createNonCompliant工厂方法，它从TestPublisher.Violation枚举中接受一个值或者多个值。这些值规定了发布者可以忽略规范的哪些部分： REQUEST_OVERFLOW：即使请求不足，也允许调用next，不会抛IllegalStateException ALLOW_NULL：对于null，也允许调用next，不会抛NullPointerException CLEANUP_ON_TERMINATE：允许发送多次终止信号。包括complete()、 error()和emit() DEFER_CANCELLATION：允许忽略cancel信号，继续发送信号 TestPublisher会在订阅以后跟踪内部状态，以使用assert*方法。 Checking the Execution Path with PublisherProbe当构建复杂operators链的时候，可能会有多个执行路径，对应不同的子序列。大多数情况下，这些子序列能够生产足够的onNext信号，可以执行到最后。比如下面的例子，如果源是空的，就使用switchIfEmpty： 123456public Flux&lt;String&gt; processOrFallback(Mono&lt;String&gt; source, Publisher&lt;String&gt; fallback) &#123; return source .flatMapMany(phrase -&gt; Flux.fromArray(phrase.split(\"\\\\s+\"))) .switchIfEmpty(fallback);&#125;12345 很容易测试switchIfEmpty对应的逻辑分支： 1234567891011121314@Testpublic void testSplitPathIsUsed() &#123; StepVerifier.create(processOrFallback(Mono.just(\"just a phrase with tabs!\"), Mono.just(\"EMPTY_PHRASE\"))) .expectNext(\"just\", \"a\", \"phrase\", \"with\", \"tabs!\") .verifyComplete();&#125;@Testpublic void testEmptyPathIsUsed() &#123; StepVerifier.create(processOrFallback(Mono.empty(), Mono.just(\"EMPTY_PHRASE\"))) .expectNext(\"EMPTY_PHRASE\") .verifyComplete();&#125;12345678910111213 但是，考虑另一个例子，方法生产的是Mono。它等待源完成，执行附加任务，然后完成。如果源是空的，执行Runnable类型的任务： 12345678910private Mono&lt;String&gt; executeCommand(String command) &#123; return Mono.just(command + \" DONE\");&#125;public Mono&lt;Void&gt; processOrFallback(Mono&lt;String&gt; commandSource, Mono&lt;Void&gt; doWhenEmpty) &#123; return commandSource .flatMap(command -&gt; executeCommand(command).then()) //then()忘记了command的返回。它只关心已经完成了 .switchIfEmpty(doWhenEmpty); //如何区分两个都是空序列的情况&#125;123456789 为了验证processOrFallback确实执行了doWhenEmpty路径，你需要写boilerplate。就是说，你需要一个Mono ： 它确实被订阅了 整个处理结束后，断言该事实 在 3.1之前，你需要为每个想要断言的状态，手工维护一个AtomicBoolean，并将相应的doOn*回调附加到要评估的发布者。从3.1.0开始，可以使用PublisherProbe： 123456789101112@Testpublic void testCommandEmptyPathIsUsed() &#123; PublisherProbe&lt;Void&gt; probe = PublisherProbe.empty(); //翻译空序列 StepVerifier.create(processOrFallback(Mono.empty(), probe.mono())) //使用probe.mono()代替Mono&lt;Void&gt; .verifyComplete(); probe.assertWasSubscribed(); //序列完成后，确保使用了probe probe.assertWasRequested(); //以及实际请求的数据 probe.assertWasNotCancelled(); //没有被取消&#125;1234567891011 本方法，对Flux&lt; T &gt;也有效。对于需要探测执行路径，也需要探测数据的情况，你可以使用PublisherProbe.of(Publisher)包装任何Publisher&lt; T &gt;。","tags":[{"name":"reactor","slug":"reactor","permalink":"http://yoursite.com/tags/reactor/"}],"categories":[{"name":"reactor","slug":"reactor","permalink":"http://yoursite.com/categories/reactor/"}]},{"title":"dubbo 问题","date":"2019-07-07T01:56:06.439Z","path":"wiki/dubbo/dubbo 问题/","text":"dubbo 问题1.dubbo adapter 如何实现动态切换服务实现者 A.通过动态代理 B.通过适配器 加 URL BUS C.通过动态代理加URL BUS 2.dubbo filter 如何动态扩展业务功能 A.改写ProtocolFilterWrapper B.加protocol装饰类 C.在Meta-INF扩充 3.dubbo 不同功能使用不同协议是如何实现 A.扩充protocl接口协议，指定protocol名，由ExtensionLoader来获取 B.直接通过ExtensionLoader 加载指定协议 C.全自动匹配 4.dubbo cluster 服务容错如何实现 A.根据failfast,failover,failback 等策略，通过异常分支决心决定如何选择invoker交互 最终决定result状态 B.调用invoker失败直接返回异常,由业务处理异常流程 C.通过router 过滤 invoker集合 再负载均衡调用，遇见异常走不同的回调策略或mock 5.dubbo 负载均衡权重 如何动态变更 A.zk回调provider通知invoker 权重值变更,负载均衡获得最新invoker权重进行负载调用 B.zk回调provider通知invoker的method权重值变更,负载均衡获得最新invoker method权重进行负载调用 C.通过api直接动态改变 2.6 Sofa dubbo sentinel nacos seata etcd Rocket MQ Kafka grpc Rsocket 1.RPC 通信原理 RPC 是什么&amp;底层原理是什么&amp;解决什么问题[API调用弊端]&amp;怎么实现 RPC核心基础功能具备哪几个？ RPC框架在项目中的根本作用 RPC为什么不能用HTTP协议，而是RPC协议 服务治理是什么东东？服务怎么治理？","tags":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/tags/netty/"}],"categories":[{"name":"dubbo","slug":"dubbo","permalink":"http://yoursite.com/categories/dubbo/"}]},{"title":"Java-NIO","date":"2019-06-12T07:56:26.913Z","path":"wiki/netty/Java NIO/","text":"Java NIOBufferJava NIO 中的 Buffer 用于和 NIO 通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 Buffer的基本用法使用 Buffer 读写数据一般遵循以下四个步骤 1.写入数据到Buffer 2.调用 flip() 方法 3.从 Buffer 中读取数据 4.调用 clear() 方法或者 compact() 方法 当向 buffer 写入数据是，buffer 会记录下写了多少数据。一旦要读取数据，需要通过 flip() 方法将 Buffer 从写的模式切换到读的模式。在读的模式下，可以读取之前写入到 buffer 的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。有两种方式能清空缓冲区：调用clear() 或 compact() 方法。 clear() 方法会清空整个缓冲区。compact() 方法只会清除已经读过的数据。任何未读的数据都被迁到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 下面是一个使用Buffer 的例子 12345678910111213141516RandomAccessFile aFile = new RandomAccessFile(\"/nio-dta.txt\",\"rw\");FileChannel inChannel = aFile.getChannel();//create buffer with capacity of 48 bytesByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);//read into bufferwhile(bytesRead != -1)&#123; buf.flip();//make buffer ready for read while(buf.hasRemaining())&#123; System.out.print((char)buf.get());//read 1 byte at a time &#125; buf.clear();//make buffer ready for writing bytesRead = inChannel.read(buf);&#125;aFile.close(); Buffer的capacity，position和limit缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer 对象，并提供了一组方法，用来方便的访问该块内存。 为了理解 Buffer 的工作原理，需要熟悉它的三个属性： capacity position limit position 和 limit 的含义取决于 Buffer 处在读模式还是写模式。不管 Buffer 处在什么模式，capacity 的含义总是一样的。关于capacity ， position 和 limit 在读写模式中的说明如下： capacity 作为一个内存块，Buffer 有一个固定的大小值，也叫”capacity”。你只能往里写 capacity 个 byte 、long、char 等类型。一旦 Buffer 满了，需要将其清空(通过读数据或者清除数据) 才能继续写数据往里写数据。 position 当你写数据到 Buffer 中时，position 表示当前的位置。初始的position 值为 0 。当一个byte、long等数据写到 Buffer 后，position 会向前移动到下一个可插入数据的 Buffer 单元。 position 最大可为 capacity -1. 当读取数据是，也是从某个特定位置读。当将 Buffer 从写模式切换到读模式，position 会被重置为 0 ，当从 Buffer 的position 处读取数据时， position 向前移动到下一个可读取的位置。 limit 在写模式下，Buffer 的 limit 表示你最多能往里写多少数据。写模式下，limit 等于 capacity。当切换 Buffer 到读的模式是， limit 表示最多能读取多少数据。 因此，当切换 Buffer 到读模式时，limit 会被设置成写模式下的 position 值。 Buffer的类型Java NIO 有以下 Buffer 类型 ByteBuffer、MappedByteBuffer、CharBuffer、DoubleBuffer、 FloatBuffer、IntBuffer、LongBuffer、ShortBuffer 这些 Buffer 类型代表了不同的数据类型。换句话说，可以通过char/short/int/long/float或者double 类型来操作缓冲区的字节。MppedByteBuffer有些特殊。 Buffer的分配要想获得一个 Buffer 对象首先要进行分配。每一个 Buffer 类都有一个 allocate 方法。下面是一个分配 48 字节capacity 的 ByteBuffer 的例子。 1ByteBuffer buf = ByteBuffer.allocate(48); 这是分配一个可存储1024个字符的 CharBuffer: 1CharBuffer buf = CharBuffer.allocate(1024); 向Buffer中写数据写数据到 Buffer 有两种方式: 从 Channel 写到 Buffer。 通过 Buffer 的 put() 方法写到 Buffer里。 1.从 Channel 写到 Buffer 的例子 1int byteRead = inChannel.read(buf);//read intO buffer. 2.通过 put() 方法写到 Buffer 的例子： 1buf.put(127); put 方法有很多版本，允许以不同的方式把数据写入到 Buffer 中。 例如，写到一个指定的位置，或者把一个字节数组写入到 Buffer 。 更多 Buffer 实现的细节参考 JavaDoc。 flip()方法flip() 方法将 Buffer 从写模式切换到读模式。 调用 flip() 方法会将 position 设回 0，并将 limit 设置成之前 position 的值。换句话说，position 现在用于标记读的位置，limit 表示之前写进了多少个byte、char 等—现在能读取多少个byte、char 等。 从Buffer中读取数据从 Buffer 中读取数据有两种方式： 1.从 Buffer 读取数据到 Channel。 12&gt;//read from buffer into channel.&gt;int bytesWritten = inChannel.write(buf); 2.使用 get() 方法从 Buffer 中读取数据。 1&gt;byte aByte = buf.get(); get() 方法有很多版本，允许你以不同的方式从 Buffer 中读取数据。 例如，从指定 position 读取，或者从 Buffer 中读取数据到字节数组。更多参考JavaDoc. rewind() 方法 Buffer.rewind() 将 position 设回 0，所以你可以重读 Buffer 中的所有数据。 limit 保持不变，任然表示能从 Buffer 中读取多少个元素。 clear() 与compact()方法一旦读完 Buffer 中的数据， 需要让 Buffer 准备好再次被写入。可以通过 clear() 或 compact() 方法来实现。 如果调用的事 clear() 方法，position 将被设回0，limit 被设置成 capacity 的值。换句话说，Buffer 被清空了，Buffer 中的数据并未清除，只是这些标记告诉我们可以从哪里开始往 Buffer 里写数据。 如果 Buffer 中有一些未读的数据，调用 clear() 方法，数据将”被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。 如果 Buffer 中仍有未读取的数据， 且后续还需要这些数据，但是此时想要先先写些数据，那么使用 compact() 方法。 compact() 方法将所有未读取的数据拷贝到 Buffer 起始处。然后 position 设到最后一个未读元素正后面。limit 属性依然像 clear() 方法一样，设置成capacity。现在 Buffer 准备写数据了，但是不会覆盖未读的数据。 mark()与reset()方法通过调用 Buffer.mark() 方法，可以标记Buffer 中一个特定 position. 之后可以通过调用 Buffer.reset() 方法恢复到这个 position 。 123buffer.mark();//call buffer.get() a couple of times, e.g during parsing.buffer.reset();//set position back to mark. equals()与compareTo()方法equals() 方法 equals() 方法只是比较 Buffer 的一部分，不是每一个在它里面的元素都比较。实际上，它只比较 Buffer 中的剩余元素。当满足下列条件时，表示两个 Buffer 相等： 1.有相同的类型(byte、char、int 等)。 2.Buffer 中剩余的byte、char等的个数相等。 3.Buffer 中所有剩余的byte、char等都相同。 compareTo() 方法 compareTo() 方法比较两个 Buffer 的剩余元素(byte、char等)，如果满足下列条件，则认为一个 Buffer “小于” 另一个 Buffer： 1.第一个不相等的元素小于另一个Buffer 中对应的元素。 2.所有元素都相等，但第一个Buffer 比另一个先耗尽(第一个 Buffer 的元素个数比另一个少)。","tags":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/tags/netty/"}],"categories":[{"name":"netty","slug":"netty","permalink":"http://yoursite.com/categories/netty/"}]}]}